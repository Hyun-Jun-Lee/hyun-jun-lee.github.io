---
title: "대규모 분산처리 프레임워크 정리"
date: 2024-01-10
category: [DATA,]
tag: [data engineer,bigdata]
---

"빅데이터를 지탱하는 기술" 을 읽으며 알게된 정보 정리


## Hadoop

Hadoop은 대규모 데이터 세트의 저장 및 처리를 위해 설계된 오픈소스 분산 처리 시스템이다. 
이 시스템은 크게 HDFS, YARN, 그리고 MapReduce의 세 가지 핵심 구성 요소로 이루어져 있으며, 이 외에도 Hive, Tez, Impala, Presto 등과 같은 다양한 프로젝트가 Hadoop 생태계를 구성하고 있다.

- HDFS(Hadoop Distributed File System) : 분산 파일 시스템
- YARN(Yet Another Resource Negotiator) : 리소스 관리자
- MapReduce : 분산데이터 처리에 활용

### HDFS

HDFS는 데이터를 여러 서버에 걸쳐 저장함으로써 고가용성과 신뢰성을 제공한다. 
데이터는 여러 블록으로 나뉘어 저장되며, 각 블록은 네트워크에 있는 여러 노드에 복제되어 장애 발생 시에도 데이터 손실을 방지한다.

### YARN

YARN은 클러스터의 컴퓨팅 리소스를 관리하고, 작업을 컨테이너 단위로 할당하여 실행한다. 
각 컨테이너는 필요한 CPU, 메모리 등의 리소스를 할당받으며, YARN은 이러한 컨테이너를 여러 노드에 분산시켜 작업을 실행한다. 
YARN은 높은 수준의 확장성과 유연성을 제공하여 다양한 데이터 처리 작업을 효율적으로 관리할 수 있다

* 도커의 컨테이너는 OS 수준의 가상화 기술이고, YARN의 컨테이너는 어떤 호스트에서 어떤 프로세스를 실행시킬지에 대한 기술이다.

### MapReduce

MapReduce는 데이터를 처리하고 분석하기 위한 프로그래밍 모델이다. 
이는 큰 데이터 세트를 Map(매핑) 단계에서 키-값 쌍으로 처리하고, Reduce(리듀스) 단계에서 이러한 쌍들을 요약하거나 집계하는 방식으로 동작한다. 
MapReduce는 배치 처리에 최적화되어 있으며, 대규모 데이터 분석 작업을 위해 많이 쓰인다.

### Hive

Hive 또한 YARN 컨테이너 상에서 실행되는 분산 어플리케이션 중 하나로, 데이터 처리를 실행하는데 사용된다. 
Hive는 Hadoop 상에서 SQL과 유사한 HiveQL 쿼리 언어를 사용하여 데이터를 질의하고 분석할 수 있는 데이터 웨어하우스 인프라이다. 사용자는 SQL과 유사한 쿼리를 작성할 수 있으며, Hive는 이를 MapReduce, Tez 또는 Spark 작업으로 변환하여 실행한다.

#### Hive On Tez

Hive on Tez는 Hive의 기본 데이터 처리 엔진인 MapReduce를 Tez로 대체하여 성능을 향상시킨 구성이다. Tez는 DAG(Directed Acyclic Graph)를 기반으로 작업을 최적화하고, 연산이 끝난 데이터를 즉시 후속 작업으로 전달하여 전체 쿼리 실행 시간을 단축시킨다

### Impala, Presto

Impala와 Presto는 대화형의 쿼리 실행을 위해 개발 된 소프트웨어이다. 

- 대화형 쿼리(interactive querying) : 사용자가 쿼리를 제출하고 거의 실시간으로 결과를 받을 수 있는 쿼리 실행 방식, 대화형 쿼리를 지원하는 시스템은 빠른 응답 시간을 제공하기 위해 메모리 내 처리, 최적화된 쿼리 엔진, 적절한 데이터 인덱싱과 같은 다양한 기술을 활용함

Impala와 Presto는 대규모 데이터 세트에 대해 SQL 쿼리를 거의 실시간으로 실행할 수 있도록 설계된 분산 SQL 쿼리 엔진으로,Hadoop 기반 데이터에 대한 대화형 쿼리를 가능하게 하여 사용자가 대용량의 데이터에 대해 빠르게 질의하고 결과를 받을 수 있게 해준다. 

반면, Tez는 더 일반적인 데이터 처리 프레임워크로 주로 배치 처리 작업에 최적화되어 있고 대화형 쿼리보다는 복잡한 데이터 처리 파이프라인을 효율적으로 실행하기 위해 설계되었다.

## Spark

Apache Spark는 대규모 데이터 처리를 위한 오픈소스 분산 컴퓨팅 시스템이고 MapReduce 모델을 대체할 수 있는 더 빠르고, 범용적인 데이터 처리 엔진으로 설계되었다. 

- 인메모리 처리(In-Memory Processing): Spark의 가장 큰 특징은 데이터를 메모리에 적재하여 처리하는 것이고, 이를 통해 디스크 기반의 데이터 처리보다 훨씬 빠른 속도를 실현한다. 이는 반복적인 알고리즘을 실행하는 머신러닝과 같은 작업에서 특히 유용

- RDD(Resilient Distributed Dataset): 네트워크에 걸쳐 분산된 데이터 컬렉션으로, 오류가 발생해도 자동으로 복구될 수 있도록 설계되었다. RDD는 immutable한 특성을 가지며, 이를 통해 데이터의 안정성과 병렬 처리 효율성을 높인다.

    - immutable하면 안전성과 병렬처리 효율성이 높아지는 이유?
        - 데이터가 불변한다는 것이 보장되면 정확성과 일관성이 유지되기 때문에 안정성이 높아짐
        - 데이터가 변경되지 않기 때문에, 여러 스레드나 프로세스가 동일한 데이터에 동시에 접근해도 데이터 무결성을 보장할 수 있기에 병렬처리에 적합
        - 불변객체는 오류 발생시 원본으로 되돌리기 쉽고 캐싱, 재사용에 최적화되어 있다.

- 다양한 언어 지원: Spark는 Scala에서 시작되었지만, Python, Java, R과 같은 다양한 프로그래밍 언어를 지원한다.

- 다양한 데이터 소스와의 통합: Spark는 HDFS, S3, Cassandra, HBase, Kafka 등 다양한 데이터 소스와 함께 이용할 수 있다.

- 유연성과 확장성: Spark는 소규모 데이터 세트에서부터 페타바이트급 데이터 세트까지 다양한 규모의 데이터를 처리할 수 있는 높은 확장성을 가지고 있고 클라우드 환경과 온프레미스 환경 모두에서 구동할 수 있다.